# Deep Agents API

A production-ready FastAPI implementation of Deep Agents using LangGraph and LangChain. Deep Agents are capable of handling long-horizon tasks through planning, context offloading, and sub-agent delegation.

## üöÄ Quick Start

```bash
# 1. Navigate to project
cd deepagents

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY or ANTHROPIC_API_KEY

# 4. Run the server
python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000

# 5. Open your browser
# Navigate to: http://localhost:8000
```

That's it! The web UI will load automatically at **http://localhost:8000** and you can start chatting with the agent.

> üí° **Tip**: The UI is served directly from the FastAPI server - no separate frontend server needed!

## Features

- **Task Planning**: Maintains TODO lists for complex multi-step workflows
- **Virtual Filesystem**: Stores information in a virtual filesystem for context management
- **Tool Execution**: Executes filesystem and planning tools with state management
- **Persistent Memory**: Thread-based conversation memory using LangGraph checkpointing
- **Web UI**: Modern, responsive web interface for interacting with the agent
- **Production-Ready**: Comprehensive error handling, logging, and API best practices

## Architecture

```
deepagents/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI application entry point
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # API routes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ v1/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ endpoints/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ agent.py # Agent endpoints
‚îÇ   ‚îú‚îÄ‚îÄ core/                # Core configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ agents/              # Agent logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.py         # LangGraph definition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py         # State definition
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools/           # Agent tools
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ filesystem.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ planning.py
‚îÇ   ‚îî‚îÄ‚îÄ schemas/             # Pydantic models
‚îÇ       ‚îî‚îÄ‚îÄ agent.py
‚îú‚îÄ‚îÄ ui/                      # Web UI
‚îÇ   ‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îÇ   ‚îî‚îÄ‚îÄ static/
‚îÇ       ‚îú‚îÄ‚îÄ css/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ style.css
‚îÇ       ‚îî‚îÄ‚îÄ js/
‚îÇ           ‚îî‚îÄ‚îÄ app.js
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

### What's Included

```
deepagents/
‚îú‚îÄ‚îÄ app/                    # Backend (FastAPI + LangGraph)
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Application entry (serves UI + API)
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ agents/            # Agent logic + tools
‚îÇ   ‚îú‚îÄ‚îÄ api/               # REST API endpoints
‚îÇ   ‚îî‚îÄ‚îÄ schemas/           # Pydantic models
‚îú‚îÄ‚îÄ ui/                     # Frontend (HTML/CSS/JS)
‚îÇ   ‚îú‚îÄ‚îÄ templates/         # HTML templates
‚îÇ   ‚îî‚îÄ‚îÄ static/            # CSS + JavaScript
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ .env.example          # Configuration template
‚îî‚îÄ‚îÄ README.md             # This file
```

## Installation

1. **Clone or navigate to the project**:
   ```bash
   cd deepagents
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment variables**:
   ```bash
   cp .env.example .env
   # Edit .env and add your API keys
   ```

## Configuration

Create a `.env` file with the following variables:

```env
# You only need ONE API key (OpenAI OR Anthropic, not both required)
# Priority: OpenAI is checked first, then Anthropic
OPENAI_API_KEY=your_openai_api_key_here
# OR
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Server configuration (optional)
HOST=0.0.0.0
PORT=8000

# Model configuration (optional)
DEFAULT_MODEL=gpt-4o  # Used with OpenAI
DEFAULT_ANTHROPIC_MODEL=claude-3-5-sonnet-20240620  # Used with Anthropic
```

> üí° **Why both?** The system supports both providers for flexibility, but you only need **one** API key. Choose based on your preference:
> - **OpenAI (GPT-4o)**: Fast, cost-effective, great for general tasks
> - **Anthropic (Claude 3.5 Sonnet)**: Excellent reasoning, better for complex analysis

## Usage

### Starting the Server

```bash
python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Or using the main module:

```bash
python3 app/main.py
```

The server will start on http://localhost:8000

### Using the Web UI

Once the server is running, simply open your browser and navigate to:

**http://localhost:8000**

> üé® The UI loads automatically - no additional setup needed!

The web UI provides:
- üí¨ **Chat Interface**: Interact with the agent through a modern chat interface
- üìÅ **File Viewer**: View and browse files created by the agent
- ‚úì **TODO Tracker**: Monitor task progress with status indicators
- ‚öôÔ∏è **Settings**: Configure the API URL

**Features**:
- Real-time updates of files and TODOs
- Markdown-style message formatting
- Persistent conversation threads
- Responsive design for mobile and desktop

### API Endpoints

You can also interact directly with the API:

#### 1. Invoke Agent

**POST** `/api/v1/agent/invoke`

Invoke the Deep Agent with a query.

**Request Body**:
```json
{
  "query": "Create a plan to learn Rust, write it to plan.txt, and add the first step to TODOs.",
  "thread_id": "optional-thread-id"
}
```

**Response**:
```json
{
  "response": "I have created the plan and added the first task.",
  "thread_id": "abc-123",
  "files": {
    "plan.txt": "1. Learn Rust basics\n2. Build a project"
  },
  "todos": [
    {"task": "Learn Rust basics", "status": "pending"}
  ]
}
```

#### 2. Get Agent State

**GET** `/api/v1/agent/{thread_id}/state`

Retrieve the current state of an agent thread.

**Response**:
```json
{
  "thread_id": "abc-123",
  "messages": [...],
  "files": {...},
  "todos": [...]
}
```

#### 3. Health Check

**GET** `/health`

Check if the API is running.

### Interactive API Documentation

Once the server is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## Agent Capabilities

### Planning Tools

- `plan_read_todos()`: Read the current TODO list
- `plan_add_todo(task: str)`: Add a new task to the TODO list
- `plan_update_todo(index: int, status: str)`: Update task status (pending/in_progress/completed)

### Filesystem Tools

- `fs_read_file(path: str)`: Read file content
- `fs_write_file(path: str, content: str)`: Write content to a file
- `fs_ls(path: str)`: List files in the virtual filesystem

## Example Usage

### Python Client

```python
import httpx

# Invoke the agent
response = httpx.post(
    "http://localhost:8000/api/v1/agent/invoke",
    json={
        "query": "Research LangGraph and write a summary to summary.md"
    },
    timeout=60.0
)

data = response.json()
print(f"Response: {data['response']}")
print(f"Files: {data['files']}")
print(f"TODOs: {data['todos']}")

# Get state
thread_id = data['thread_id']
state = httpx.get(f"http://localhost:8000/api/v1/agent/{thread_id}/state")
print(state.json())
```

### cURL

```bash
# Invoke agent
curl -X POST "http://localhost:8000/api/v1/agent/invoke" \
  -H "Content-Type: application/json" \
  -d '{"query": "Create a TODO list for building a web app"}'

# Get state
curl "http://localhost:8000/api/v1/agent/{thread_id}/state"
```

## Development

### Running Tests

```bash
python3 test_agent.py
```

### Project Structure

- **app/main.py**: FastAPI application with CORS, logging, and lifespan management
- **app/agents/graph.py**: LangGraph agent implementation with tool execution
- **app/agents/state.py**: TypedDict state definition for the agent
- **app/agents/tools/**: Tool implementations (filesystem, planning)
- **app/api/v1/endpoints/**: API endpoint definitions
- **app/core/config.py**: Configuration management using Pydantic Settings
- **app/schemas/**: Pydantic models for request/response validation

## Best Practices Implemented

1. **Modular Architecture**: Clear separation of concerns (API, agents, tools, config)
2. **Type Safety**: Full type hints and Pydantic models
3. **Error Handling**: Comprehensive try-catch blocks with proper HTTP status codes
4. **Logging**: Structured logging throughout the application
5. **Configuration**: Environment-based configuration with sensible defaults
6. **Documentation**: Docstrings, type hints, and API documentation
7. **State Management**: Thread-based conversation memory with LangGraph checkpointing

## Technologies Used

- **FastAPI**: Modern, fast web framework for building APIs
- **LangGraph**: Framework for building stateful, multi-actor applications with LLMs
- **LangChain**: Framework for developing applications powered by language models
- **Pydantic**: Data validation using Python type annotations
- **Uvicorn**: ASGI server for running FastAPI applications

## License

This project is part of the LLM development workspace.

## Additional Documentation

- **[UI Guide](UI_GUIDE.md)**: Detailed guide on accessing the UI and understanding API key configuration
- **[UI Comparison](UI_COMPARISON.md)**: Comparison between our UI and the official deep-agents-ui
- **[Enhancements](docs/ENHANCEMENTS.md)**: List of all enhancements made to the project
- **[Test Documentation](tests/README.md)**: How to run the comprehensive test suite

## ‚ö†Ô∏è UI Note: Official vs Our Implementation

**Important:** Our UI at `http://localhost:8000` is **different** from the official [deep-agents-ui](https://github.com/langchain-ai/deep-agents-ui):

- **Official UI**: Next.js/React app that connects to LangGraph deployments (requires separate LangGraph server)
- **Our UI**: Simple HTML/JS integrated with our FastAPI backend (single server, no build step)

See [UI_COMPARISON.md](UI_COMPARISON.md) for detailed differences and when to use each.

## References

- [LangChain Deep Agents](https://github.com/langchain-ai/deepagents)
- [Deep Agents from Scratch](https://github.com/langchain-ai/deep-agents-from-scratch)
- [Deep Agents UI](https://github.com/langchain-ai/deep-agents-ui)
